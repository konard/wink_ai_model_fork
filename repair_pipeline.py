# -*- coding: utf-8 -*-
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–µ–π—Ç–∏–Ω–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ü–µ–Ω —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º.
–ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
–∏ –∏–∑–±–µ–≥–∞–µ—Ç –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –ø—Ä–∏ –ø—Ä–æ—Å—Ç–æ–º –ø–æ–∏—Å–∫–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤.
"""

import re
import json
from pathlib import Path
from typing import List, Dict, Any, Tuple
import numpy as np
from sentence_transformers import SentenceTransformer, util
from tqdm import tqdm

# PDF parsing
try:
    import PyPDF2
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False
    print("WARNING: PyPDF2 not installed. PDF support disabled. Install with: pip install PyPDF2")

# ===== REFERENCE CONTEXTS FOR SEMANTIC ANALYSIS =====
# –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Å—Ü–µ–Ω (English and Russian)
CONTEXT_TEMPLATES = {
    'graphic_violence': [
        "brutal murder with blood and gore",
        "torture and physical violence causing injury",
        "graphic depiction of death and killing",
        "violent assault with weapons causing harm",
        # Russian
        "–∂–µ—Å—Ç–æ–∫–æ–µ —É–±–∏–π—Å—Ç–≤–æ —Å –∫—Ä–æ–≤—å—é –∏ —É–≤–µ—á—å—è–º–∏",
        "–ø—ã—Ç–∫–∏ –∏ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ –Ω–∞—Å–∏–ª–∏–µ –ø—Ä–∏—á–∏–Ω—è—é—â–µ–µ —Ç—Ä–∞–≤–º—ã",
        "–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–º–µ—Ä—Ç–∏ –∏ —É–±–∏–π—Å—Ç–≤–∞",
        "–Ω–∞—Å–∏–ª—å—Å—Ç–≤–µ–Ω–Ω–æ–µ –Ω–∞–ø–∞–¥–µ–Ω–∏–µ —Å –æ—Ä—É–∂–∏–µ–º –ø—Ä–∏—á–∏–Ω—è—é—â–µ–µ –≤—Ä–µ–¥"
    ],
    'stylized_action': [
        "heroic action scene with combat",
        "adventure movie fight sequence",
        "comic book style action without gore",
        "spy thriller chase and combat",
        "superhero saving people from danger",
        # Russian
        "–≥–µ—Ä–æ–∏—á–µ—Å–∫–∞—è –±–æ–µ–≤–∞—è —Å—Ü–µ–Ω–∞ —Å —Å—Ä–∞–∂–µ–Ω–∏–µ–º",
        "–ø—Ä–∏–∫–ª—é—á–µ–Ω—á–µ—Å–∫–∞—è —Å—Ü–µ–Ω–∞ –¥—Ä–∞–∫–∏ –≤ —Ñ–∏–ª—å–º–µ",
        "—ç–∫—à–Ω –≤ —Å—Ç–∏–ª–µ –∫–æ–º–∏–∫—Å–æ–≤ –±–µ–∑ –∂–µ—Å—Ç–æ–∫–æ—Å—Ç–∏",
        "–ø–æ–≥–æ–Ω—è –∏ –±–æ–π –≤ —à–ø–∏–æ–Ω—Å–∫–æ–º —Ç—Ä–∏–ª–ª–µ—Ä–µ",
        "—Å—É–ø–µ—Ä–≥–µ—Ä–æ–π —Å–ø–∞—Å–∞—é—â–∏–π –ª—é–¥–µ–π –æ—Ç –æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
    ],
    'sexual_content': [
        "explicit sexual intercourse scene",
        "nudity in sexual context",
        "rape or sexual assault",
        "graphic sexual activity",
        # Russian
        "—è–≤–Ω–∞—è —Å—Ü–µ–Ω–∞ –ø–æ–ª–æ–≤–æ–≥–æ –∞–∫—Ç–∞",
        "–Ω–∞–≥–æ—Ç–∞ –≤ —Å–µ–∫—Å—É–∞–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ",
        "–∏–∑–Ω–∞—Å–∏–ª–æ–≤–∞–Ω–∏–µ –∏–ª–∏ —Å–µ–∫—Å—É–∞–ª—å–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ",
        "–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è —Å–µ–∫—Å—É–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
    ],
    'mild_romance': [
        "romantic kissing and affection",
        "love scene without explicit content",
        "romantic relationship development",
        # Russian
        "—Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ—Ü–µ–ª—É–∏ –∏ –Ω–µ–∂–Ω–æ—Å—Ç—å",
        "–ª—é–±–æ–≤–Ω–∞—è —Å—Ü–µ–Ω–∞ –±–µ–∑ —ç–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
        "—Ä–∞–∑–≤–∏—Ç–∏–µ —Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π"
    ],
    'horror_violence': [
        "horror movie with scary violence",
        "psychological terror and fear",
        "monster attack with blood",
        "slasher film with killing",
        # Russian
        "—Ñ–∏–ª—å–º —É–∂–∞—Å–æ–≤ —Å –ø—É–≥–∞—é—â–∏–º –Ω–∞—Å–∏–ª–∏–µ–º",
        "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ç–µ—Ä—Ä–æ—Ä –∏ —Å—Ç—Ä–∞—Ö",
        "–Ω–∞–ø–∞–¥–µ–Ω–∏–µ –º–æ–Ω—Å—Ç—Ä–∞ —Å –∫—Ä–æ–≤—å—é",
        "—Å–ª—ç—à–µ—Ä —Å —É–±–∏–π—Å—Ç–≤–∞–º–∏"
    ],
    'profanity_context': [
        "casual conversation with swearing",
        "aggressive confrontation with profanity",
        "repeated use of strong language",
        # Russian
        "–Ω–µ–ø—Ä–∏–Ω—É–∂–¥–µ–Ω–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä —Å –º–∞—Ç–æ–º",
        "–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∫–æ–Ω—Ñ—Ä–æ–Ω—Ç–∞—Ü–∏—è —Å –Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–æ–π –ª–µ–∫—Å–∏–∫–æ–π",
        "–º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—Ä–µ–ø–∫–∏—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"
    ],
    'drug_abuse': [
        "drug use and addiction",
        "substance abuse scene",
        "characters taking illegal drugs",
        # Russian
        "—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –Ω–∞—Ä–∫–æ—Ç–∏–∫–æ–≤ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å",
        "—Å—Ü–µ–Ω–∞ –∑–ª–æ—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –≤–µ—â–µ—Å—Ç–≤–∞–º–∏",
        "–ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –ø—Ä–∏–Ω–∏–º–∞—é—â–∏–µ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –Ω–∞—Ä–∫–æ—Ç–∏–∫–∏"
    ],
    'child_endangerment': [
        "child in dangerous situation",
        "violence involving minors",
        "child abuse or threat to children",
        # Russian
        "—Ä–µ–±–µ–Ω–æ–∫ –≤ –æ–ø–∞—Å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏",
        "–Ω–∞—Å–∏–ª–∏–µ —Å —É—á–∞—Å—Ç–∏–µ–º –Ω–µ—Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–ª–µ—Ç–Ω–∏—Ö",
        "–∂–µ—Å—Ç–æ–∫–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ —Å –¥–µ—Ç—å–º–∏ –∏–ª–∏ —É–≥—Ä–æ–∑–∞ –¥–µ—Ç—è–º"
    ],
    'discussion_violence': [
        "courtroom discussion of crime",
        "testimony about violent event",
        "describing past violence in dialogue",
        "academic or legal discussion of weapons",
        "demonstration or explanation without action",
        # Russian
        "–æ–±—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ –∑–∞–ª–µ —Å—É–¥–∞",
        "–ø–æ–∫–∞–∑–∞–Ω–∏—è –æ –Ω–∞—Å–∏–ª—å—Å—Ç–≤–µ–Ω–Ω–æ–º —Å–æ–±—ã—Ç–∏–∏",
        "–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—à–ª–æ–≥–æ –Ω–∞—Å–∏–ª–∏—è –≤ –¥–∏–∞–ª–æ–≥–µ",
        "–∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–µ –∏–ª–∏ –ø—Ä–∞–≤–æ–≤–æ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –æ—Ä—É–∂–∏—è",
        "–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏–ª–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –±–µ–∑ –¥–µ–π—Å—Ç–≤–∏—è"
    ],
    'thriller_tension': [
        "psychological thriller with suspense",
        "tense dramatic confrontation",
        "mystery investigation without violence",
        "courtroom drama legal arguments",
        # Russian
        "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ç—Ä–∏–ª–ª–µ—Ä —Å –Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ–º",
        "–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–∞—è –¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Ñ—Ä–æ–Ω—Ç–∞—Ü–∏—è",
        "—Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ç–∞–π–Ω—ã –±–µ–∑ –Ω–∞—Å–∏–ª–∏—è",
        "—Å—É–¥–µ–±–Ω–∞—è –¥—Ä–∞–º–∞ –ø—Ä–∞–≤–æ–≤—ã–µ —Å–ø–æ—Ä—ã"
    ]
}

# ===== KEYWORD PATTERNS (English and Russian) =====
VIOLENCE_WORDS = [
    # English patterns
    r'\bkill\w*', r'\bshoot\w*', r'\bshot\b', r'\bstab\w*',
    r'\bknife\b', r'\bgun\w*', r'\bpistol\b', r'\brifle\b',
    r'\bexplod\w*', r'\bblast\w*', r'\battack\w*',
    r'\bbeating\b', r'\bbeaten\b', r'\bbeats\b',  # Exclude "a beat" (screenplay term)
    r'\bcorpse\b', r'\bdead\b', r'\bmurder\w*', r'\bviolence\b',
    r'\bterrorist\b', r'\bhostage\b', r'\brip(ped|s)? apart\b',
    r'\bthug(s)?\b', r'\bterror\b', r'\bfight(ing)?\b',
    r'\bbattle(s|d)?\b', r'\bwar\b', r'\bshoot[- ]?out\b',
    r'\bexplosion\b', r'\bgrenade\b',
    # Russian patterns
    r'\b—É–±–∏–π\w*', r'\b—É–±–∏—Ç—å\b', r'\b—É–±–∏–ª\w*', r'\b—É–±–∏–≤–∞\w*',
    r'\b—Å—Ç—Ä–µ–ª—è\w*', r'\b–≤—ã—Å—Ç—Ä–µ–ª\w*', r'\b–∑–∞—Å—Ç—Ä–µ–ª\w*',
    r'\b–∑–∞—Ä–µ–∑\w*', r'\b–Ω–æ–∂\b', r'\b–æ—Ä—É–∂\w+', r'\b–ø–∏—Å—Ç–æ–ª–µ—Ç\w*',
    r'\b–≤–∏–Ω—Ç–æ–≤–∫\w*', r'\b–∞–≤—Ç–æ–º–∞—Ç\w*', r'\b–≤–∑—Ä—ã–≤\w*',
    r'\b–∞—Ç–∞–∫\w*', r'\b–Ω–∞–ø–∞–¥–µ\w*', r'\b–∏–∑–±–∏–µ\w*',
    r'\b—Ç—Ä—É–ø\w*', r'\b–º–µ—Ä—Ç–≤\w*', r'\b–ø–æ–≥–∏–±\w*',
    r'\b–Ω–∞—Å–∏–ª–∏–µ\b', r'\b–∂–µ—Å—Ç–æ–∫\w*', r'\b—Ç–µ—Ä—Ä–æ—Ä\w*',
    r'\b–∑–∞–ª–æ–∂–Ω–∏–∫\w*', r'\b–±–∞–Ω–¥–∏—Ç\w*', r'\b–¥—Ä–∞–∫\w*',
    r'\b–±–æ–π\b', r'\b—Å—Ä–∞–∂\w*', r'\b–≤–æ–π–Ω–∞\b', r'\b–±–æ–µ–≤\w*',
    r'\b–≥—Ä–∞–Ω–∞—Ç\w*', r'\b–±–æ–º–±\w*'
]

GORE_WORDS = [
    # English patterns
    r'\bblood\b', r'\bbloody\b', r'\bbloodied\b', r'\bbleeding\b',
    r'\bcorpse\b', r'\bwound\b', r'\bscar\b', r'\binjur\w*',
    r'\bcrash\w*', r'\bburn\w*', r'\bguts\b', r'\bentrails\b',
    r'\bbrain\b', r'\bdead body\b', r'\bgore\b', r'\bmutilat\w*',
    # Russian patterns
    r'\b–∫—Ä–æ–≤\w*', r'\b–∫—Ä–æ–≤–∞–≤\w*', r'\b–∫—Ä–æ–≤–æ—Ç–æ—á\w*',
    r'\b—Ä–∞–Ω\w+', r'\b—à—Ä–∞–º\w*', r'\b—É–≤–µ—á—å\w*',
    r'\b–æ–∂–æ–≥\w*', r'\b–∫–∏—à–∫\w*', r'\b–≤–Ω—É—Ç—Ä–µ–Ω–Ω–æ—Å—Ç\w*',
    r'\b–º–æ–∑–≥\w*', r'\b—Ä–∞—Å—á–ª–µ–Ω–µ–Ω\w*', r'\b–∏–∑—É–≤–µ—á\w*'
]

PROFANITY = [
    # English patterns
    r'\bfuck\b', r'\bshit\b', r'\bmotherfucker\b', r'\bbitch\b',
    r'\basshole\b', r'\bdamn\b', r'\bhell\b', r'\bcrap\b',
    # Russian patterns
    r'\b–±–ª—è–¥—å\b', r'\b–±–ª—è\b', r'\b—Å—É–∫–∞\b', r'\b—Ö—É–π\b',
    r'\b–ø–∏–∑–¥\w*', r'\b–µ–±–∞—Ç—å\b', r'\b–µ–±–∞–ª\w*', r'\b–µ–±–∞–Ω\w*',
    r'\b–∑–∞–µ–±\w*', r'\b–¥–µ—Ä—å–º\w*', r'\b–≥–æ–≤–Ω\w*', r'\b—Ö–µ—Ä\w*',
    r'\b–º—É–¥–∞–∫\w*', r'\b—Å–≤–æ–ª–æ—á\w*', r'\b—Ç–≤–∞—Ä—å\b'
]

DRUG_WORDS = [
    # English patterns
    r'\bdrug(s)?\b', r'\bheroin\b', r'\bcocaine\b', r'\bmarijuana\b',
    r'\bpill(s)?\b', r'\bweed\b', r'\balcohol\b', r'\bdrunk\b',
    r'\bcigarette\b', r'\bsmok(e|ing)\b', r'\baddiction\b',
    # Russian patterns
    r'\b–Ω–∞—Ä–∫–æ—Ç\w*', r'\b–≥–µ—Ä–æ–∏–Ω\w*', r'\b–∫–æ–∫–∞–∏–Ω\w*', r'\b–º–∞—Ä–∏—Ö—É–∞–Ω\w*',
    r'\b—Ç—Ä–∞–≤–∫\w*', r'\b–¥–æ–ø\w*', r'\b—Ç–∞–±–ª–µ—Ç–∫\w*', r'\b–ø–∏–ª—é–ª\w*',
    r'\b–∞–ª–∫–æ–≥–æ–ª\w*', r'\b—Å–ø–∏—Ä—Ç\w*', r'\b–≤—ã–ø–∏–≤\w*', r'\b–ø—å—è–Ω\w*',
    r'\b—Å–∏–≥–∞—Ä–µ—Ç\w*', r'\b–∫—É—Ä\w*', r'\b–∑–∞–≤–∏—Å–∏–º\w*', r'\b–Ω–∞–∫—É—Ä\w*'
]

CHILD_WORDS = [
    # English patterns
    r'\bchild(ren)?\b', r'\bkid(s)?\b', r'\bson\b', r'\bdaughter\b',
    r'\bteen(aged)?\b', r'\bboy\b', r'\bgirl\b', r'\bminor\b',
    # Russian patterns
    r'\b—Ä–µ–±–µ–Ω–æ–∫\b', r'\b—Ä–µ–±–µ–Ω–∫\w*', r'\b–¥–µ—Ç\w+', r'\b–º–∞–ª—ã—à\w*',
    r'\b—Å—ã–Ω\b', r'\b–¥–æ—á\w*', r'\b–ø–æ–¥—Ä–æ—Å—Ç–æ–∫\w*', r'\b–º–∞–ª—å—á–∏–∫\w*',
    r'\b–¥–µ–≤–æ—á–∫\w*', r'\b–Ω–µ—Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–ª–µ—Ç–Ω\w*'
]

NUDITY_WORDS = [
    # English patterns
    r'\bbra\b', r'\bpanty|panties\b', r'\bunderwear\b', r'\bnaked\b',
    r'\bnude\b', r'\bundress\w*', r'\btopless\b',
    # Russian patterns
    r'\b–≥–æ–ª—ã–π\b', r'\b–≥–æ–ª–∞—è\b', r'\b–Ω–∞–≥\w*', r'\b–æ–±–Ω–∞–∂\w*',
    r'\b–±—é—Å—Ç–≥–∞–ª—å—Ç–µ—Ä\w*', r'\b—Ç—Ä—É—Å\w*', r'\b–±–µ–ª—å–µ\b',
    r'\b—Ä–∞–∑–¥–µ–≤–∞\w*', r'\b–±–µ–∑ –æ–¥–µ–∂–¥\w*'
]

SEX_WORDS = [
    # English patterns
    r'\brape\b', r'\bsexual\b', r'\bintercourse\b', r'\bsex scene\b',
    r'\bmolest\b', r'\borgasm\b', r'\bmake love\b', r'\bhaving sex\b',
    r'\bsexually\b', r'\bbed\s+scene\b',
    # Russian patterns
    r'\b–∏–∑–Ω–∞—Å–∏–ª–æ–≤\w*', r'\b–Ω–∞—Å–∏–ª–æ–≤\w*', r'\b—Å–µ–∫—Å—É–∞–ª—å–Ω\w*',
    r'\b–ø–æ–ª–æ–≤\w+\s+–∞–∫—Ç\w*', r'\b–∏–Ω—Ç–∏–º–Ω\w*', r'\b–æ—Ä–≥–∞–∑–º\w*',
    r'\b–∑–∞–Ω–∏–º–∞—é—Ç—Å—è\s+—Å–µ–∫—Å–æ–º\b', r'\b–∑–∞–Ω–∏–º–∞–ª–∏—Å—å\s+–ª—é–±–æ–≤—å—é\b',
    r'\b–ø–æ—Å—Ç–µ–ª—å–Ω\w+\s+—Å—Ü–µ–Ω\w*'
]

# ===== INITIALIZATION =====
print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
MODEL_NAME = "all-MiniLM-L6-v2"
embedder = SentenceTransformer(MODEL_NAME)

# –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤
print("–ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
context_embeddings = {}
for context_type, templates in CONTEXT_TEMPLATES.items():
    context_embeddings[context_type] = embedder.encode(
        templates,
        convert_to_numpy=True,
        show_progress_bar=False
    )
print("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.\n")


def count_pattern_matches(patterns: List[str], text: str) -> Tuple[int, List[str]]:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –æ—Ç —Ñ–∏–≥—É—Ä–∞–ª—å–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π.

    Returns:
        (count, matched_excerpts)
    """
    # –§—Ä–∞–∑—ã-–∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å—á–∏—Ç–∞—é—Ç—Å—è –∑–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ/–∫–æ–Ω—Ç–µ–Ω—Ç
    FALSE_POSITIVES = [
        # English patterns
        r'if (it|that|this) kills',
        r'(it|that|this)\'ll kill',
        r'(it|that|this) (will|would) kill',
        r'gonna.*kill',  # "gonna get the brass ring if it kills him"
        r'kill (you|me|him|her|them|us)',  # Figurative "kills you/me"
        r'make love',  # –ù–µ—ç–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
        r'kill time',
        r'dressed to kill',
        r'killer instinct',
        r'lady killer',
        r'killing me softly',
        r'shoot the breeze',
        r'shoot for',
        r'shot in the dark',
        r'long shot',
        r'shot at',  # –ü–æ–ø—ã—Ç–∫–∞/—à–∞–Ω—Å (like "got a shot at")
        r'light[ -]?shot',
        r'fight (for|to see|to|for the)',  # –ú–µ—Ç–∞—Ñ–æ—Ä–∞ –±–æ—Ä—å–±—ã
        r'fighting (for|against)',  # "fighting for bread crumbs"
        r'won the war',  # –ú–µ—Ç–∞—Ñ–æ—Ä–∞ –ø–æ–±–µ–¥—ã
        r'war (ration|time|era|years)',  # Historical context
        r'(world|civil|cold) war',
        r'battles? (with|against|for)',  # –ú–µ—Ç–∞—Ñ–æ—Ä–∏—á–µ—Å–∫–∞—è –±–æ—Ä—å–±–∞
        r'attack(ed|ing)? (the|a) problem',
        r'speed of light',  # –§–∏–∑–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        r'explosion of',  # "explosion of wood" (not literal explosion)
        r'explod(e|ed|ing) (with|into)',  # Figurative
        r'fight back tears',
        r'fight for (justice|freedom|rights)',
        r'fighting? (cancer|disease|illness)',
        r'dead serious',  # Figurative
        r'pool table',  # "shot" in pool context
        r'bank shot',  # Pool/basketball
        r'\ba beat\b',  # Screenplay term for pause
        r'as if.*\b(molest|rape|seduce|fondle)',  # Hypothetical/comparative (not actual content)
        r'about to.*\b(molest|rape|seduce|fondle)',  # Prevented/hypothetical action
        r'were to.*\b(molest|rape|seduce)',  # Conditional/hypothetical
        r'would.*\b(molest|rape|seduce)',  # Hypothetical
        r'brain (garbage|dump|drain|power|wave|dead|cell|teaser)',  # Metaphorical/non-gore brain usage
        r'brain(s)? (are|is) (just|garbage|trash)',  # "brains are just garbage"
        # Russian patterns
        r'–≤ –∫—É—Ä—Å–µ',  # "–≤ –∫—É—Ä—Å–µ" = "aware of/know about" (not drugs)
        r'–∫—É—Ä—Ç–æ–∫',  # "–∫—É—Ä—Ç–∫–∞" = "jacket" (not smoking)
        r'–∫—É—Ä—Ç–∫\w',  # "–∫—É—Ä—Ç–∫–∞" variations
        r'–æ–±—Ä–∏—Ç—ã–π –Ω–∞–≥–æ–ª–æ',  # "–æ–±—Ä–∏—Ç—ã–π –Ω–∞–≥–æ–ª–æ" = "shaved bald" (not nudity)
        r'–Ω–∞–≥–æ–ª–æ',  # "–Ω–∞–≥–æ–ª–æ" = "bald/clean-shaven" (when not about nudity)
        r'—Ç–∞–±–ª–µ—Ç–∫\w+\s+(–æ—Ç|–¥–ª—è|–ø—Ä–æ—Ç–∏–≤)',  # "—Ç–∞–±–ª–µ—Ç–∫–∏ –æ—Ç/–¥–ª—è" = medicine pills (not drugs)
        r'–±–æ–ª–µ—É—Ç–æ–ª\w+',  # "–±–æ–ª–µ—É—Ç–æ–ª—è—é—â–µ–µ" = painkiller (medicine, not drugs)
        r'–∫—Ä–æ–≤–∞—Ç\w*',  # "–∫—Ä–æ–≤–∞—Ç—å/–∫—Ä–æ–≤–∞—Ç–∏" = "bed" (not blood/gore)
        r'–∫—Ä–æ–≤[–∞–æ]\w*',  # "–∫—Ä–æ–≤–∞/–∫—Ä–æ–≤–æ–º" = "shelter/roof" (not blood)
    ]

    false_positive_patterns = [re.compile(p, re.I) for p in FALSE_POSITIVES]

    matches = []
    count = 0
    for pattern in patterns:
        regex = re.compile(pattern, re.I)
        found = regex.finditer(text)
        for match in found:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (50 —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ)
            start = max(0, match.start() - 50)
            end = min(len(text), match.end() + 50)
            excerpt = text[start:end].strip()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ª–æ–∂–Ω—ã–º —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ–º
            is_false_positive = any(fp.search(excerpt) for fp in false_positive_patterns)

            if not is_false_positive:
                matches.append(excerpt)
                count += 1

    # Additional context-based filtering: if excerpt is very short (< 10 chars)
    # it's likely a parsing artifact
    matches = [m for m in matches if len(m.strip()) > 10]
    return count, matches[:5]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–æ 5 –ø—Ä–∏–º–µ—Ä–æ–≤


def analyze_scene_context(scene_text: str) -> Dict[str, float]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ü–µ–Ω—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤.
    """
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å—Ü–µ–Ω—ã
    scene_embedding = embedder.encode(
        [scene_text],
        convert_to_numpy=True,
        show_progress_bar=False
    )[0]

    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –∫–∞–∂–¥—ã–º —Ç–∏–ø–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    context_scores = {}
    for context_type, template_embeddings in context_embeddings.items():
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –∫–∞–∂–¥—ã–º —à–∞–±–ª–æ–Ω–æ–º
        similarities = util.cos_sim(scene_embedding, template_embeddings)[0]
        # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        context_scores[context_type] = float(similarities.max())

    return context_scores


def extract_scene_features(scene_text: str) -> Dict[str, Any]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ü–µ–Ω—ã, –≤–∫–ª—é—á–∞—è –ø–æ–¥—Å—á–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    –∏ –ø—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.
    """
    txt = scene_text.lower()

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∏ —Å–æ–±–∏—Ä–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    violence_count, violence_excerpts = count_pattern_matches(VIOLENCE_WORDS, txt)
    gore_count, gore_excerpts = count_pattern_matches(GORE_WORDS, txt)
    profanity_count, profanity_excerpts = count_pattern_matches(PROFANITY, txt)
    drugs_count, drugs_excerpts = count_pattern_matches(DRUG_WORDS, txt)
    child_count, child_excerpts = count_pattern_matches(CHILD_WORDS, txt)
    nudity_count, nudity_excerpts = count_pattern_matches(NUDITY_WORDS, txt)
    sex_count, sex_excerpts = count_pattern_matches(SEX_WORDS, txt)

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
    context_scores = analyze_scene_context(scene_text)

    length = max(1, len(txt.split()))

    return {
        'violence_count': violence_count,
        'violence_excerpts': violence_excerpts,
        'gore_count': gore_count,
        'gore_excerpts': gore_excerpts,
        'profanity_count': profanity_count,
        'profanity_excerpts': profanity_excerpts,
        'drugs_count': drugs_count,
        'drugs_excerpts': drugs_excerpts,
        'child_count': child_count,
        'child_excerpts': child_excerpts,
        'nudity_count': nudity_count,
        'nudity_excerpts': nudity_excerpts,
        'sex_count': sex_count,
        'sex_excerpts': sex_excerpts,
        'length': length,
        'context_scores': context_scores
    }


def normalize_and_contextualize_scores(features: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∫–æ—Ä—Ä–µ–∫—Ü–∏—é.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –æ—Ü–µ–Ω–æ–∫.
    """
    L = features['length']
    ctx = features['context_scores']

    # –ë–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –¥–ª–∏–Ω–µ —Å—Ü–µ–Ω—ã
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Ä–∞–∑—É–º–Ω—É—é —Ñ–æ—Ä–º—É–ª—É: (count / length) * scale_factor
    # –≠—Ç–æ –¥–∞–µ—Ç –ø–ª–∞–≤–Ω—É—é –æ—Ü–µ–Ω–∫—É –≤–º–µ—Å—Ç–æ —Å–∫–∞—á–∫–æ–≤ –æ—Ç 0 –∫ 1
    violence_density = features['violence_count'] / max(1, L)
    gore_density = features['gore_count'] / max(1, L)

    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º: 1 —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –Ω–∞ 50 —Å–ª–æ–≤ = 0.2, –Ω–∞ 25 —Å–ª–æ–≤ = 0.4, –Ω–∞ 10 —Å–ª–æ–≤ = 1.0
    violence_raw = violence_density * 100
    gore_raw = gore_density * 100

    # –ö–û–ù–¢–ï–ö–°–¢–ù–ê–Ø –ö–û–†–†–ï–ö–¶–ò–Ø —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–µ–º–∞–Ω—Ç–∏–∫–∏

    violence_multiplier = 1.0
    gore_multiplier = 1.0

    # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ/–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞—Å–∏–ª–∏—è, –∞ –Ω–µ —Ä–µ–∞–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
    if ctx['discussion_violence'] > 0.55 or ctx['thriller_tension'] > 0.5:
        violence_multiplier *= 0.3  # –°–∏–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ–º
        gore_multiplier *= 0.3

    # –ï—Å–ª–∏ —Å—Ü–µ–Ω–∞ –±–æ–ª—å—à–µ –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —ç–∫—à–Ω, —Å–Ω–∏–∂–∞–µ–º –æ—Ü–µ–Ω–∫—É –Ω–∞—Å–∏–ª–∏—è
    elif ctx['stylized_action'] > 0.5:
        violence_multiplier *= 0.6
        gore_multiplier *= 0.7

    # –ï—Å–ª–∏ —Å—Ü–µ–Ω–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –Ω–∞—Å–∏–ª–∏–µ, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ—Ü–µ–Ω–∫—É
    if ctx['graphic_violence'] > 0.6:
        violence_multiplier *= 1.3
        gore_multiplier *= 1.4

    # –ï—Å–ª–∏ —Å—Ü–µ–Ω–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Ö–æ—Ä—Ä–æ—Ä, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏
    if ctx['horror_violence'] > 0.55:
        violence_multiplier *= 1.2
        gore_multiplier *= 1.3

    violence_score = min(1.0, violence_raw * violence_multiplier)
    gore_score = min(1.0, gore_raw * gore_multiplier)

    # –°–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç - –µ—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    sex_raw = features['sex_count']
    if ctx['sexual_content'] > 0.6 and sex_raw > 0:
        sex_score = min(1.0, sex_raw * 1.5)
    elif ctx['mild_romance'] > 0.5:
        sex_score = min(0.3, sex_raw * 0.5)  # –ú—è–≥–∫–∞—è —Ä–æ–º–∞–Ω—Ç–∏–∫–∞
    else:
        sex_score = min(1.0, sex_raw)

    # –ù–∞–≥–æ—Ç–∞
    nudity_score = min(1.0, features['nudity_count'] / 3.0)

    # –ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞
    profanity_score = min(1.0, features['profanity_count'] / (L / 100))

    # –ù–∞—Ä–∫–æ—Ç–∏–∫–∏
    if ctx['drug_abuse'] > 0.55:
        drugs_score = min(1.0, features['drugs_count'] / 2.0)
    else:
        drugs_score = min(1.0, features['drugs_count'] / 5.0)

    # –†–∏—Å–∫ –¥–ª—è –¥–µ—Ç–µ–π
    child_risk = 0.0
    if features['child_count'] > 0:
        if ctx['child_endangerment'] > 0.5:
            child_risk = min(1.0, features['child_count'] / 2.0)
        else:
            child_risk = min(0.5, features['child_count'] / 5.0)

    return {
        'violence': violence_score,
        'gore': gore_score,
        'sex_act': sex_score,
        'nudity': nudity_score,
        'profanity': profanity_score,
        'drugs': drugs_score,
        'child_risk': child_risk,
        'context_scores': ctx,
        'excerpts': {
            'violence': features['violence_excerpts'],
            'gore': features['gore_excerpts'],
            'sex': features['sex_excerpts'],
            'nudity': features['nudity_excerpts'],  # –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–∏–º–µ—Ä—ã –Ω–∞–≥–æ—Ç—ã
            'profanity': features['profanity_excerpts'],
            'drugs': features['drugs_excerpts']
        }
    }


def generate_scene_recommendations(scene_scores: Dict[str, float], target_rating: str = None) -> List[str]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–Ω–∏–∂–µ–Ω–∏—é –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ü–µ–Ω—ã.

    Args:
        scene_scores: –û—Ü–µ–Ω–∫–∏ —Å—Ü–µ–Ω—ã (violence, gore, sex_act, nudity, profanity, drugs, child_risk)
        target_rating: –ñ–µ–ª–∞–µ–º—ã–π —Ä–µ–π—Ç–∏–Ω–≥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ü–µ–Ω—ã
    """
    recommendations = []

    # –ù–∞—Å–∏–ª–∏–µ
    if scene_scores['violence'] >= 0.7:
        recommendations.append(
            "üî™ –ù–∞—Å–∏–ª–∏–µ (–≤—ã—Å–æ–∫–æ–µ): –£–º–µ–Ω—å—à–∏—Ç–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞—Å–∏–ª–∏—è. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ü–µ–Ω—É –∑–∞ –∫–∞–¥—Ä–æ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—Ä–µ–∑–∫—É –∫–∞–¥—Ä–∞, "
            "–∑–∞–º–µ–Ω–∏—Ç—å —è–≤–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ –Ω–∞ –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ."
        )
    elif scene_scores['violence'] >= 0.4:
        recommendations.append(
            "‚öîÔ∏è –ù–∞—Å–∏–ª–∏–µ (—É–º–µ—Ä–µ–Ω–Ω–æ–µ): –°–æ–∫—Ä–∞—Ç–∏—Ç–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é —Å—Ü–µ–Ω –¥—Ä–∞–∫–∏/–∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: —É–±—Ä–∞—Ç—å –∫—Ä—É–ø–Ω—ã–µ –ø–ª–∞–Ω—ã —É–¥–∞—Ä–æ–≤, —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ü–µ–Ω—ã."
        )

    # –ö—Ä–æ–≤—å –∏ —É–≤–µ—á—å—è
    if scene_scores['gore'] >= 0.6:
        recommendations.append(
            "ü©∏ –ö—Ä–æ–≤—å/—É–≤–µ—á—å—è (–≤—ã—Å–æ–∫–æ–µ): –£–±–µ—Ä–∏—Ç–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫—Ä–æ–≤–∏ –∏ —Ä–∞–Ω. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–∞–Ω—ã –∫—Ä—É–ø–Ω—ã–º –ø–ª–∞–Ω–æ–º, —É–±—Ä–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è 'blood', 'guts', "
            "'SPLORCH', –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –±–æ–ª–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ —Ç–∏–ø–∞ '—Ä–∞–Ω–µ–Ω', '–ø–æ—Å—Ç—Ä–∞–¥–∞–ª'."
        )
    elif scene_scores['gore'] >= 0.3:
        recommendations.append(
            "üíâ –ö—Ä–æ–≤—å/—É–≤–µ—á—å—è (—É–º–µ—Ä–µ–Ω–Ω–æ–µ): –°–º—è–≥—á–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–ª–µ—Å–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: —É–º–µ–Ω—å—à–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∫—Ä–æ–≤–∏."
        )

    # –°–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
    if scene_scores['sex_act'] >= 0.6:
        recommendations.append(
            "üîû –°–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (—ç–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω—ã–π): –£–¥–∞–ª–∏—Ç–µ –∏–ª–∏ —Å–º—è–≥—á–∏—Ç–µ —è–≤–Ω—ã–µ —Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω—ã. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–Ω—Ç–∞–∂ —Å –ø–µ—Ä–µ—Ö–æ–¥–æ–º, –ø–æ–∫–∞–∑–∞—Ç—å –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü –±–µ–∑ –¥–µ—Ç–∞–ª–µ–π."
        )
    elif scene_scores['sex_act'] >= 0.3:
        recommendations.append(
            "üíã –°–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (—É–º–µ—Ä–µ–Ω–Ω—ã–π): –°–º—è–≥—á–∏—Ç–µ —Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ/—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."
        )

    # –ù–∞–≥–æ—Ç–∞
    if scene_scores['nudity'] >= 0.4:
        recommendations.append(
            "üëô –ù–∞–≥–æ—Ç–∞: –£–±–µ—Ä–∏—Ç–µ –∏–ª–∏ —Å–º—è–≥—á–∏—Ç–µ —Å—Ü–µ–Ω—ã —Å –æ–±–Ω–∞–∂–µ–Ω–Ω—ã–º —Ç–µ–ª–æ–º. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–µ–∂–¥—É, –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∫—É—Ä—Å –∫–∞–º–µ—Ä—ã, —É–±—Ä–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∏–∂–Ω–µ–≥–æ –±–µ–ª—å—è."
        )

    # –ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞
    if scene_scores['profanity'] >= 0.5:
        recommendations.append(
            "ü§¨ –ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞ (—á–∞—Å—Ç–∞—è): –ó–∞–º–µ–Ω–∏—Ç–µ –º–∞—Ç –Ω–∞ –±–æ–ª–µ–µ –º—è–≥–∫–∏–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –∑–∞–º–µ–Ω–∏—Ç—å 'fuck', 'shit', 'bitch' –Ω–∞ 'damn', 'hell' –∏–ª–∏ —ç–≤—Ñ–µ–º–∏–∑–º—ã."
        )
    elif scene_scores['profanity'] >= 0.3:
        recommendations.append(
            "üò† –ì—Ä—É–±–∞—è –ª–µ–∫—Å–∏–∫–∞: –°–æ–∫—Ä–∞—Ç–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω—ã—Ö —Å–ª–æ–≤."
        )

    # –ù–∞—Ä–∫–æ—Ç–∏–∫–∏
    if scene_scores['drugs'] >= 0.4:
        recommendations.append(
            "üíä –ù–∞—Ä–∫–æ—Ç–∏–∫–∏/–∞–ª–∫–æ–≥–æ–ª—å: –£–º–µ–Ω—å—à–∏—Ç–µ –ø–æ–∫–∞–∑ —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –≤–µ—â–µ—Å—Ç–≤. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç—å —ç–∫—Ä–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è."
        )

    # –î–µ—Ç–∏ –≤ –æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    if scene_scores['child_risk'] >= 0.5:
        recommendations.append(
            "üë∂ –î–µ—Ç–∏ –≤ –æ–ø–∞—Å–Ω–æ—Å—Ç–∏: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ! –£–±–µ—Ä–∏—Ç–µ —Å—Ü–µ–Ω—ã —Å —É–≥—Ä–æ–∑–æ–π –¥–µ—Ç—è–º. "
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –∑–∞–º–µ–Ω–∏—Ç—å –¥–µ—Ç–µ–π –Ω–∞ –≤–∑—Ä–æ—Å–ª—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, —É–±—Ä–∞—Ç—å —Å—Ü–µ–Ω—É –ø–æ–ª–Ω–æ—Å—Ç—å—é, "
            "–∏–ª–∏ –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –¥–µ—Ç–∏ –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."
        )

    if not recommendations:
        recommendations.append("‚úÖ –°—Ü–µ–Ω–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")

    return recommendations


def map_scores_to_rating(agg: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –≤ –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ (0+, 6+, 12+, 16+, 18+).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ –∏ –ø—Ä–∏—á–∏–Ω—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    """
    reasons = []
    excerpts = []
    rating = '0+'

    # 18+ - —ç–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (—Ç–æ–ª—å–∫–æ –¥–ª—è –∫—Ä–∞–π–Ω–µ –≥—Ä–∞—Ñ–∏—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
    if agg['sex_act'] >= 0.75 or agg['gore'] >= 0.95:
        rating = '18+'
        if agg['sex_act'] >= 0.75:
            reasons.append("—ç–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω—ã–µ —Å—Ü–µ–Ω—ã —Å–µ–∫—Å—É–∞–ª—å–Ω–æ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞")
            if agg['excerpts']['sex']:
                excerpts.extend(agg['excerpts']['sex'][:2])
        if agg['gore'] >= 0.95:
            reasons.append("–∫—Ä–∞–π–Ω–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∂–µ—Å—Ç–æ–∫–æ—Å—Ç–∏ –∏ —É–≤–µ—á–∏–π")
            if agg['excerpts']['gore']:
                excerpts.extend(agg['excerpts']['gore'][:2])

    # 18+ - –¥–µ—Ç–∏ –≤ –æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å –Ω–∞—Å–∏–ª–∏–µ–º
    elif agg['child_risk'] > 0.7 and (agg['sex_act'] >= 0.5 or agg['violence'] >= 0.8):
        rating = '18+'
        reasons.append("–æ–ø–∞—Å–Ω—ã–µ –∏–ª–∏ –∂–µ—Å—Ç–æ–∫–∏–µ —Å—Ü–µ–Ω—ã —Å —É—á–∞—Å—Ç–∏–µ–º –Ω–µ—Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–ª–µ—Ç–Ω–∏—Ö")
        if agg['excerpts']['violence']:
            excerpts.extend(agg['excerpts']['violence'][:2])

    # 16+ - –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ —Å –∫—Ä–æ–≤—å—é
    elif (agg['violence'] >= 0.8 and agg['gore'] >= 0.7) or agg['gore'] >= 0.75:
        rating = '16+'
        reasons.append("–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –Ω–∞—Å–∏–ª–∏–µ —Å –∫—Ä–æ–≤—å—é –∏ —É–≤–µ—á—å—è–º–∏")
        if agg['excerpts']['violence']:
            excerpts.extend(agg['excerpts']['violence'][:2])
        if agg['excerpts']['gore']:
            excerpts.extend(agg['excerpts']['gore'][:1])

    # 16+ - —è–≤–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ
    elif agg['violence'] >= 0.65 or agg['gore'] >= 0.5:
        rating = '16+'
        if agg['violence'] >= 0.65:
            reasons.append("–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ –∏ —Å—Ü–µ–Ω—ã —É–±–∏–π—Å—Ç–≤")
            if agg['excerpts']['violence']:
                excerpts.extend(agg['excerpts']['violence'][:2])
        if agg['gore'] >= 0.5:
            reasons.append("–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫—Ä–æ–≤–∏ –∏ —Ç–µ–ª–µ—Å–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")
            if agg['excerpts']['gore']:
                excerpts.extend(agg['excerpts']['gore'][:2])

    # 16+ - —Å–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ä–µ–¥–Ω–µ–π —Å—Ç–µ–ø–µ–Ω–∏
    elif agg['sex_act'] >= 0.35 or agg['nudity'] >= 0.4:
        rating = '16+'
        reasons.append("—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏ –Ω–∞–≥–æ—Ç–∞")
        if agg['excerpts']['sex']:
            excerpts.extend(agg['excerpts']['sex'][:2])
        if agg['excerpts']['nudity']:
            excerpts.extend(agg['excerpts']['nudity'][:2])

    # 12+ - —É–º–µ—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
    elif agg['violence'] >= 0.4 or agg['profanity'] >= 0.5 or agg['drugs'] >= 0.4:
        rating = '12+'
        if agg['violence'] >= 0.4:
            reasons.append("—É–º–µ—Ä–µ–Ω–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ –∏ —É–≥—Ä–æ–∑—ã")
            if agg['excerpts']['violence']:
                excerpts.extend(agg['excerpts']['violence'][:1])
        if agg['profanity'] >= 0.5:
            reasons.append("–Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞")
            if agg['excerpts']['profanity']:
                excerpts.extend(agg['excerpts']['profanity'][:1])
        if agg['drugs'] >= 0.4:
            reasons.append("—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –∞–ª–∫–æ–≥–æ–ª—è, —Ç–∞–±–∞–∫–∞ –∏–ª–∏ –Ω–∞—Ä–∫–æ—Ç–∏–∫–æ–≤")
            if agg['excerpts']['drugs']:
                excerpts.extend(agg['excerpts']['drugs'][:1])

    # 6+ - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
    elif agg['violence'] >= 0.2 or agg['profanity'] >= 0.3:
        rating = '6+'
        reasons.append("–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ –∏–ª–∏ —Ä–µ–¥–∫–∞—è –≥—Ä—É–±–∞—è –ª–µ–∫—Å–∏–∫–∞")

    # 0+ - –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≤—Å–µ—Ö
    else:
        rating = '0+'
        reasons.append("–∫–æ–Ω—Ç–µ–Ω—Ç –±–µ–∑ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π")

    return {
        'rating': rating,
        'reasons': reasons,
        'evidence_excerpts': excerpts[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 –ø—Ä–∏–º–µ—Ä–æ–≤
    }


def parse_script_to_scenes(txt: str) -> List[Dict[str, Any]]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ü–µ–Ω—ã.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ (INT./EXT.), —Ç–∞–∫ –∏ —Ä—É—Å—Å–∫–∏–µ (–ò–ù–¢./–≠–ö–°–¢.) –º–∞—Ä–∫–µ—Ä—ã —Å—Ü–µ–Ω.
    """
    scenes = []
    # –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–∏—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ —Å—Ü–µ–Ω (–ò–ù–¢./–≠–ö–°–¢.)
    parts = re.split(
        r'(?=(?:INT\.|EXT\.|–ò–ù–¢\.|–≠–ö–°–¢\.|scene_heading\s*:|SCENE HEADING\s*:))',
        txt,
        flags=re.I
    )

    idx = 0
    for p in parts:
        text = p.strip()
        if not text or len(text) < 20:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
            continue

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–∏—Ö –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ —Å—Ü–µ–Ω
        heading_match = re.match(r'((?:INT\.|EXT\.|–ò–ù–¢\.|–≠–ö–°–¢\.).{0,120})', text, flags=re.I)
        heading = heading_match.group(1).strip() if heading_match else f"scene_{idx}"

        scenes.append({
            'scene_id': idx,
            'heading': heading,
            'text': text
        })
        idx += 1

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ü–µ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–Ω—É —Å—Ü–µ–Ω—É
    if len(scenes) < 3:
        scenes = [{'scene_id': 0, 'heading': 'full_script', 'text': txt}]

    return scenes


def extract_text_from_pdf(pdf_path: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞.

    Args:
        pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É

    Returns:
        –¢–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞
    """
    if not PDF_SUPPORT:
        raise ImportError("PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å –ø–æ–º–æ—â—å—é: pip install PyPDF2")

    text = []
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ PDF: {len(pdf_reader.pages)} —Å—Ç—Ä–∞–Ω–∏—Ü")

            for page_num, page in enumerate(pdf_reader.pages):
                page_text = page.extract_text()
                if page_text:
                    text.append(page_text)

        return '\n'.join(text)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF: {e}")
        raise


def analyze_script_file(path: str) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å—Ü–µ–Ω–∞—Ä–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã (.txt) –∏ PDF (.pdf).

    Args:
        path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å—Ü–µ–Ω–∞—Ä–∏—è (.txt –∏–ª–∏ .pdf)

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º, –ø—Ä–∏—á–∏–Ω–∞–º–∏ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ —á–∏—Ç–∞–µ–º
    file_path = Path(path)
    if file_path.suffix.lower() == '.pdf':
        print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω PDF —Ñ–∞–π–ª: {file_path.name}")
        txt = extract_text_from_pdf(str(file_path))
    else:
        # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        txt = file_path.read_text(encoding='utf-8', errors='ignore')

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ü–µ–Ω—ã
    scenes = parse_script_to_scenes(txt)
    print(f"–ù–∞–π–¥–µ–Ω–æ —Å—Ü–µ–Ω: {len(scenes)}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã
    print("–ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω...")
    features = []
    for scene in tqdm(scenes, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ü–µ–Ω"):
        feat = extract_scene_features(scene['text'])
        features.append(feat)

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∫–æ—Ä—Ä–µ–∫—Ü–∏—é
    scores = [normalize_and_contextualize_scores(f) for f in features]

    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥: —É—á–∏—Ç—ã–≤–∞–µ–º –∫–∞–∫ –º–∞–∫—Å–∏–º—É–º, —Ç–∞–∫ –∏ —á–∞—Å—Ç–æ—Ç—É
    score_keys = ['violence', 'gore', 'sex_act', 'nudity', 'profanity', 'drugs', 'child_risk']
    agg = {}
    for k in score_keys:
        values = [s[k] for s in scores]
        max_val = float(np.max(values))
        p95_val = float(np.percentile(values, 95))
        p90_val = float(np.percentile(values, 90))

        # –î–ª—è –Ω–∞—Å–∏–ª–∏—è –∏ –∫—Ä–æ–≤–∏: –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –º–∞–∫—Å–∏–º—É–º–∞ –∏ 95-–≥–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è
        # –ï—Å–ª–∏ –µ—Å—Ç—å 1-2 –æ—á–µ–Ω—å –≥—Ä–∞—Ñ–∏—á–Ω—ã–µ —Å—Ü–µ–Ω—ã, –Ω–æ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ - —ç—Ç–æ 16+, –∞ –Ω–µ 18+
        # –ï—Å–ª–∏ –º–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω - —ç—Ç–æ 18+
        if k in ['violence', 'gore']:
            # 70% –º–∞–∫—Å–∏–º—É–º + 30% p95 –¥–∞–µ—Ç –±–∞–ª–∞–Ω—Å
            agg[k] = max_val * 0.7 + p95_val * 0.3

        # –î–ª—è —Å–µ–∫—Å—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –Ω–∞–≥–æ—Ç—ã - –±–æ–ª—å—à–µ –≤–µ—Å –Ω–∞ –º–∞–∫—Å–∏–º—É–º
        elif k in ['sex_act', 'nudity', 'child_risk']:
            agg[k] = max_val * 0.85 + p90_val * 0.15

        # –î–ª—è –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –ª–µ–∫—Å–∏–∫–∏ –∏ –Ω–∞—Ä–∫–æ—Ç–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º 90-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å
        # —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è —á–∞—â–µ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞
        else:
            agg[k] = float(np.percentile(values, 90))

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –≤—Å–µ—Ö —Å—Ü–µ–Ω
    all_excerpts = {
        'violence': [],
        'gore': [],
        'sex': [],
        'nudity': [],  # –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–∏–º–µ—Ä—ã –Ω–∞–≥–æ—Ç—ã
        'profanity': [],
        'drugs': []
    }
    for s in scores:
        for key in all_excerpts.keys():
            all_excerpts[key].extend(s['excerpts'][key])

    agg['excerpts'] = {k: v[:5] for k, v in all_excerpts.items()}  # –¢–æ–ø-5 –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–π—Ç–∏–Ω–≥
    rating_info = map_scores_to_rating(agg)

    # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å—Ü–µ–Ω—ã
    ranking = []
    for scene, score in zip(scenes, scores):
        weight = (
            score['violence'] * 0.5 +
            score['gore'] * 0.8 +
            score['sex_act'] * 0.9 +
            score['profanity'] * 0.3 +
            score['drugs'] * 0.3 +
            score['child_risk'] * 0.7
        )
        ranking.append((weight, scene, score))

    ranking.sort(reverse=True, key=lambda x: x[0])

    # –¢–æ–ø-5 —Å–∞–º—ã—Ö –≤–ª–∏—è—é—â–∏—Ö –Ω–∞ —Ä–µ–π—Ç–∏–Ω–≥ —Å—Ü–µ–Ω
    top_scenes = []
    for weight, scene, score in ranking[:5]:
        if weight > 0.1:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ —Å—Ü–µ–Ω—ã
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º–Ω–æ–π —Å—Ü–µ–Ω—ã
            recommendations = generate_scene_recommendations(score)

            top_scenes.append({
                'scene_id': scene['scene_id'],
                'heading': scene['heading'],
                'sample_text': scene['text'][:300].replace('\n', ' ') + '...',
                'weight': round(float(weight), 3),
                'scores': {k: round(score[k], 2) for k in score_keys},
                'recommendations': recommendations
            })

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = {
        'file': str(Path(path).name),
        'predicted_rating': rating_info['rating'],
        'reasons': rating_info['reasons'],
        'evidence_excerpts': rating_info['evidence_excerpts'],
        'aggregated_scores': {k: round(agg[k], 3) for k in score_keys},
        'top_trigger_scenes': top_scenes,
        'total_scenes': len(scenes)
    }

    return result


if __name__ == '__main__':
    import sys

    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python repair_pipeline.py <–ø—É—Ç—å_–∫_—Å—Ü–µ–Ω–∞—Ä–∏—é.txt>")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python repair_pipeline.py dataset/BERT_annotations/A_Clockwork_Orange_0066921_anno.txt")
        sys.exit(0)

    script_path = sys.argv[1]

    if not Path(script_path).exists():
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª '{script_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)

    print(f"\n{'='*70}")
    print(f"–ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏—è: {script_path}")
    print(f"{'='*70}\n")

    result = analyze_script_file(script_path)

    print(f"\n{'='*70}")
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
    print(f"{'='*70}\n")
    print(json.dumps(result, ensure_ascii=False, indent=2))
